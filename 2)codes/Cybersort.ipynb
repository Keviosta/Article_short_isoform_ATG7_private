{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A)  Whole gene expression preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B)  Dataframe preparation for CIBERSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need symbol for Cibersort\n",
    "df_ciber = df_gexprProteinCoding_alNomination.copy()\n",
    "print(\"shape:\", df_ciber.shape)\n",
    "\n",
    "#remove the column I don't want\n",
    "df_ciber = df_ciber.drop(df_ciber.columns[[0, 2, 3]], axis=1)\n",
    "print(df_ciber.shape)\n",
    "\n",
    "#See how many NaN and remove them\n",
    "print(\"NaN in symbol:\", df_ciber['hgnc_symbol'].isna().sum())\n",
    "df_ciber = df_ciber.dropna(axis=0)\n",
    "print(\"after remove NaN:\", df_ciber.shape)\n",
    "\n",
    "#how many duplicate and remove\n",
    "print(\"Duplicate in symbol:\",df_ciber.duplicated(subset=[\"hgnc_symbol\"]).sum())\n",
    "df_ciber.drop_duplicates(subset = \"hgnc_symbol\", inplace = True)\n",
    "print(\"after remove Duplicate:\", df_ciber.shape)\n",
    "\n",
    "#transpose the table \n",
    "df_ciber = numpy.transpose(df_ciber)\n",
    "\n",
    "#Change head column & delete the name of the column index; choose symbol\n",
    "df_ciber.columns = df_ciber.iloc[0]\n",
    "df_ciber.columns.name = None\n",
    "df_ciber = df_ciber.reset_index()\n",
    "\n",
    "#delete row 0\n",
    "df_ciber = df_ciber.drop(df_ciber.index[0])\n",
    "\n",
    "#Column rename\n",
    "df_ciber.rename(columns = {'index' : 'sample'}, inplace = True)\n",
    "df_ciber.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the two df to have isoform expression + whole gene expression \n",
    "df_cibersort = dfisof_3organs.merge(df_ciber, on= 'sample')\n",
    "\n",
    "print(len(dfisof_3organs))\n",
    "print(len(df_ciber))\n",
    "print(len(df_cibersort))\n",
    "\n",
    "#create a column to have the 2 information\n",
    "df_cibersort['Info'] = df_cibersort[['Sample_Type', 'Primary_Site']].agg('-'.join, axis=1)\n",
    "\n",
    "#move the column to rank 1 \n",
    "col = df_cibersort.pop(\"Info\")\n",
    "df_cibersort.insert(1, \"Info\", col)\n",
    "\n",
    "#Remove all columns between column index 1 to 18\n",
    "df_cibersort.drop(df_cibersort.iloc[:, 2:25], inplace = True, axis = 1)\n",
    "\n",
    "# cannot be log for Cibersort\n",
    "col_list = df_cibersort.iloc[:,2:]\n",
    "for col in col_list:\n",
    "    df_cibersort[col] = pow(2,df_cibersort[col])+0.000001\n",
    "\n",
    "df_cibersort.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) All of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For groupby, all of them\n",
    "#choose the index column and transpose\n",
    "df_cibersortgroup = df_cibersort.set_index('Info').T\n",
    "\n",
    "#delete name of column index\n",
    "df_cibersortgroup.columns.name = None\n",
    "\n",
    "#delete the sample column\n",
    "df_cibersortgroup = df_cibersortgroup.drop(df_cibersortgroup.index[0])\n",
    "df_cibersortgroup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouby to have one column per condition to have small table\n",
    "df_cibersortgroup = df_cibersortgroup.astype(float)\n",
    "df_cibersortgroup = df_cibersortgroup.groupby(by=df_cibersortgroup.columns, axis=1).agg(numpy.median)\n",
    "df_cibersortgroup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#be sure have not negative values\n",
    "(df_cibersortgroup < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download table\n",
    "df_cibersortgroup.to_csv('df_cibersort.txt', header=True, index=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) High/Low expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column to have the 2 information\n",
    "HL_iso1['Inform'] = HL_iso1[['Sample_Type', 'Primary_Site', \"L/H\"]].agg('-'.join, axis=1)\n",
    "HL_iso2['Inform'] = HL_iso2[['Sample_Type', 'Primary_Site', \"L/H\"]].agg('-'.join, axis=1)\n",
    "\n",
    "#move the column to rank 1 \n",
    "col = HL_iso1.pop(\"Inform\")\n",
    "HL_iso1.insert(0, \"Inform\", col)\n",
    "\n",
    "col = HL_iso2.pop(\"Inform\")\n",
    "HL_iso2.insert(0, \"Inform\", col)\n",
    "HL_iso2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the two df to have isoform expression + whole gene expression (inner to only keep what is similar)\n",
    "df_cibersort_HL1 = pandas.merge(HL_iso1, df_cibersort, on= 'sample', how='inner')\n",
    "df_cibersort_HL2 = pandas.merge(HL_iso2, df_cibersort, on= 'sample', how='inner')\n",
    "\n",
    "print(\"HL_iso1:\", HL_iso1.shape)\n",
    "print(\"cybersort:\", df_cibersort.shape)\n",
    "print(\"final 1:\",df_cibersort_HL1.shape)\n",
    "\n",
    "print(\"HL_iso2:\", HL_iso2.shape)\n",
    "print(\"cybersort:\", df_cibersort.shape)\n",
    "print(\"final 2:\", df_cibersort_HL2.shape)\n",
    "\n",
    "#Remove all columns between column index 1 to 18\n",
    "df_cibersort_HL1.drop(df_cibersort_HL1.iloc[:, 2:27], inplace = True, axis = 1)\n",
    "df_cibersort_HL2.drop(df_cibersort_HL2.iloc[:, 2:27], inplace = True, axis = 1)\n",
    "\n",
    "df_cibersort_HL1 = df_cibersort_HL1.drop(['sample'],  axis = 1) \n",
    "df_cibersort_HL2 = df_cibersort_HL2.drop(['sample'],  axis = 1) \n",
    "df_cibersort_HL1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## groupby, isoform expression \n",
    "#choose the index column and transpose\n",
    "df_cibersort_HL1 = df_cibersort_HL1.set_index('Inform').T\n",
    "df_cibersort_HL2 = df_cibersort_HL2.set_index('Inform').T\n",
    "\n",
    "#delete name of column index\n",
    "df_cibersort_HL1.columns.name = None\n",
    "df_cibersort_HL2.columns.name = None\n",
    "\n",
    "#delete the sample column\n",
    "# df_cibersort_HL1 = df_cibersort_HL1.drop(df_cibersort_HL1.index[0])\n",
    "# df_cibersort_HL2 = df_cibersort_HL2.drop(df_cibersort_HL2.index[0])\n",
    "\n",
    "#grouby to have one column per condition to have small table\n",
    "df_cibersort_HL1 = df_cibersort_HL1.astype(float)\n",
    "df_cibersort_HL2 = df_cibersort_HL2.astype(float)\n",
    "\n",
    "#groupby \n",
    "df_cibersort_HL1_group = df_cibersort_HL1.groupby(by=df_cibersort_HL1.columns, axis=1).agg(numpy.median)\n",
    "df_cibersort_HL2_group = df_cibersort_HL2.groupby(by=df_cibersort_HL2.columns, axis=1).agg(numpy.median)\n",
    "df_cibersort_HL1_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#be sure have not negative value\n",
    "print(\"ciber_hl1:\",(df_cibersort_HL1_group < 0).sum().sum())\n",
    "print(\"ciber_hl2:\",(df_cibersort_HL2_group < 0).sum().sum())\n",
    "\n",
    "#download table BUT TOO HEAVY FOR CIBERSORT\n",
    "df_cibersort_HL1_group.to_csv('df_cibersort_HL1_group.txt', header=True, index=True, sep='\\t')\n",
    "df_cibersort_HL2_group.to_csv('df_cibersort_HL2_group.txt', header=True, index=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for stat, separate per tissue and isoform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cibersort_HL1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for stat, separate per tissue and isoform\n",
    "panc_HL1_H = df_cibersort_HL1['Normal Tissue-Pancreas-High']\n",
    "panc_HL1_L = df_cibersort_HL1['Normal Tissue-Pancreas-Low']\n",
    "liver_HL1_H = df_cibersort_HL1['Normal Tissue-Liver-High']\n",
    "liver_HL1_L = df_cibersort_HL1['Normal Tissue-Liver-Low']\n",
    "kidney_HL1_H = df_cibersort_HL1['Normal Tissue-Kidney-High']\n",
    "kidney_HL1_L = df_cibersort_HL1['Normal Tissue-Kidney-Low']\n",
    "\n",
    "\n",
    "panc_HL2_H = df_cibersort_HL2['Normal Tissue-Pancreas-High']\n",
    "panc_HL2_L = df_cibersort_HL2['Normal Tissue-Pancreas-Low']\n",
    "liver_HL2_H = df_cibersort_HL2['Normal Tissue-Liver-High']\n",
    "liver_HL2_L = df_cibersort_HL2['Normal Tissue-Liver-Low']\n",
    "kidney_HL2_H = df_cibersort_HL2['Normal Tissue-Kidney-High']\n",
    "kidney_HL2_L = df_cibersort_HL2['Normal Tissue-Kidney-Low']\n",
    "\n",
    "paad_HL1_H = df_cibersort_HL1['Primary Tumor-Pancreas-High']\n",
    "paad_HL1_L = df_cibersort_HL1['Primary Tumor-Pancreas-Low']\n",
    "lihc_HL1_H = df_cibersort_HL1['Primary Tumor-Liver-High']\n",
    "lihc_HL1_L = df_cibersort_HL1['Primary Tumor-Liver-Low']\n",
    "kirc_HL1_H = df_cibersort_HL1['Primary Tumor-Kidney-High']\n",
    "kirc_HL1_L = df_cibersort_HL1['Primary Tumor-Kidney-Low']\n",
    "\n",
    "paad_HL2_H = df_cibersort_HL2['Primary Tumor-Pancreas-High']\n",
    "paad_HL2_L = df_cibersort_HL2['Primary Tumor-Pancreas-Low']\n",
    "lihc_HL2_H = df_cibersort_HL2['Primary Tumor-Liver-High']\n",
    "lihc_HL2_L = df_cibersort_HL2['Primary Tumor-Liver-Low']\n",
    "kirc_HL2_H = df_cibersort_HL2['Primary Tumor-Kidney-High']\n",
    "kirc_HL2_L = df_cibersort_HL2['Primary Tumor-Kidney-Low']\n",
    "\n",
    "paad_HL2_H.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download table\n",
    "database = [panc_HL1_H, panc_HL1_L, \n",
    "            panc_HL2_H, panc_HL2_L, \n",
    "            liver_HL1_H, liver_HL1_L, \n",
    "            liver_HL2_H, liver_HL2_L,\n",
    "            paad_HL1_H, paad_HL1_L, \n",
    "            paad_HL2_H, paad_HL2_L, \n",
    "            lihc_HL1_H, lihc_HL1_L, \n",
    "            lihc_HL2_H, lihc_HL2_L,\n",
    "            kirc_HL1_H, kirc_HL1_L,\n",
    "            kirc_HL2_H, kirc_HL2_L\n",
    "            ]\n",
    "\n",
    "database_labels = ['panc_HL1_H', 'panc_HL1_L', \n",
    "            'panc_HL2_H', 'panc_HL2_L', \n",
    "            'liver_HL1_H', 'liver_HL1_L', \n",
    "            'liver_HL2_H', 'liver_HL2_L',\n",
    "            'paad_HL1_H', 'paad_HL1_L', \n",
    "            'paad_HL2_H', 'paad_HL2_L', \n",
    "            'lihc_HL1_H', 'lihc_HL1_L', \n",
    "            'lihc_HL2_H', 'lihc_HL2_L',\n",
    "            'kirc_HL1_H', 'kirc_HL1_L',\n",
    "            'kirc_HL2_H', 'kirc_HL2_L'\n",
    "            ]\n",
    "for i in range(len(database)): \n",
    "  w_df = database[i]\n",
    "  w_label = database_labels[i]\n",
    "  path = w_label + '.txt'\n",
    "\n",
    "  w_df.to_csv(path, header=True, index=True, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download table\n",
    "database = [df1, df2, df3, df4]\n",
    "\n",
    "database_labels = [\"name1\", \"name2\", \"name3\", \"name4\"]\n",
    "for i in range(len(database)): \n",
    "  w_df = database[i]\n",
    "  w_label = database_labels[i]\n",
    "  path = w_label + '.txt'\n",
    "\n",
    "  w_df.to_csv(path, header=True, index=True, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
